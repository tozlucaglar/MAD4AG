{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "C:\\MAD4AG\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd C:\\MAD4AG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import geopandas\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "file_name = f'./dbs/intermediate/stops_1_new.parquet'\n",
    "\n",
    "\n",
    "df = pd.read_parquet(file_name)\n",
    "df = df[df.holiday_s != 1]\n",
    "df = df[df.weekday_s == 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['uid', 'cluster'], keep='first', inplace=True)\n",
    "\n",
    "df['uniq_cluster_count'] = df.groupby(['uid'])['cluster'].transform('nunique')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "# read home clusters\n",
    "\n",
    "df_h = pd.read_parquet(f'./dbs/intermediate/home_inference.parquet')\n",
    "df_h.drop_duplicates(subset='uid', keep='first', inplace=True)\n",
    "df_h['home_potential'] = 1\n",
    "df_h['work_potential'] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "# read work clusters, keep only ppl having home locations\n",
    "\n",
    "df_w = pd.read_parquet(f'./dbs/intermediate/work_inference.parquet')\n",
    "df_w.drop_duplicates(subset='uid', keep='first', inplace=True)\n",
    "df_w['home_potential'] = 0\n",
    "\n",
    "ppl_having_home = df_h.uid.unique()\n",
    "df_w = df_w[df_w.uid.isin(ppl_having_home)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "# concat home and work clusters and create activity table\n",
    "\n",
    "df_act = pd.concat([df_h[['uid', 'cluster', 'home_potential', 'work_potential']], df_w[['uid', 'cluster', 'home_potential', 'work_potential']]],axis=0, ignore_index=True).sort_values(by='uid')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "# add lat and long information of the clusters\n",
    "\n",
    "df_act = pd.merge(df_act, df[['uid', 'cluster', 'cluster_lat', 'cluster_lng', 'uniq_cluster_count' ]], on=['uid', 'cluster'], how=\"left\")\n",
    "\n",
    "df_act = df_act[df_act.uniq_cluster_count>1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJCS[\"SWEREF99 TM\",GEOGCS[\"SWEREF99\",DATUM[\"SWEREF99\",SPHEROID[\"GRS 1980\",6378137,298.257222101,AUTHORITY[\"EPSG\",\"7019\"]],AUTHORITY[\"EPSG\",\"6619\"]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",15],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"3006\"]]\n",
      "epsg:4326\n"
     ]
    }
   ],
   "source": [
    "# read population by deso zones\n",
    "\n",
    "DeSO = geopandas.read_file(\n",
    "    f'C:/Synthetic_population_new/caglar/synthetic_sweden/input/deso_statistik_shp/Bef_Alder_region.shp')\n",
    "\n",
    "DeSO.loc[:, 'adult_pop'] = DeSO.loc[:, [ 'Ald20_24', 'Ald25_29', 'Ald30_34', 'Ald35_39', 'Ald40_44', 'Ald45_49', 'Ald50_54', 'Ald55_59', 'Ald60_64', 'Ald65_69', 'Ald70_74', 'Ald75_79', 'Ald80_w']].sum(axis=1) + DeSO.loc[:,'Ald16_19']/2\n",
    "\n",
    "\n",
    "print(DeSO.crs)\n",
    "\n",
    "DeSO.to_crs(4326, inplace=True)\n",
    "print(DeSO.crs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "# read employee numbers by deso zones\n",
    "# multiply the number of employees by work activity participation ratio\n",
    "\n",
    "DeSO_arb = geopandas.read_file(\n",
    "    f'C:/Synthetic_population_new/caglar/synthetic_sweden/input/deso_statistik_shp/Bef_Sysselsattning_region.shp')\n",
    "\n",
    "#DeSO_arb['county'] = DeSO_arb['Deso'].str[:1]\n",
    "DeSO_arb['county'] = DeSO_arb['Deso'].str[:2].astype(int)\n",
    "\n",
    "work_participation = pd.read_csv('dbs/intermediate/work_participation.csv',index_col=0)\n",
    "\n",
    "DeSO_arb = pd.merge(DeSO_arb, work_participation, left_on=['county'], right_on=['home_county'], how=\"left\")\n",
    "\n",
    "\n",
    "\n",
    "DeSO_arb['work_par_pop'] = DeSO_arb['Forvarb']*DeSO_arb['nunique']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "DeSO = pd.merge(DeSO, DeSO_arb[['Deso','Forvarb','work_par_pop']], left_on=['Deso'], right_on=['Deso'], how=\"left\")\n",
    "\n",
    "\n",
    "DeSO.rename(columns={'Forvarb':'employee_pop'}, inplace=True )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# add deso information to the activity table\n",
    "\n",
    "gdf_act = geopandas.GeoDataFrame(df_act, geometry=geopandas.points_from_xy(df_act.cluster_lng, df_act.cluster_lat), crs=\"EPSG:4326\")\n",
    "\n",
    "\n",
    "gdf_act = gdf_act.sjoin(DeSO[['Deso','geometry', 'adult_pop','employee_pop','work_par_pop']], how=\"left\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "# count the number of detected homes for each deso zones\n",
    "\n",
    "gdf_2_home = gdf_act[gdf_act.home_potential== 1]\n",
    "\n",
    "gdf_2_home= gdf_2_home.groupby('Deso')['uid'].count().reset_index().rename(columns={\"uid\":'home_count'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "gdf_2_home = pd.merge(DeSO[['Deso','adult_pop', 'employee_pop','work_par_pop']], gdf_2_home, left_on=['Deso'], right_on=['Deso'], how=\"left\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## calculate a weight for each device\n",
    "- we use inverse probability weighting (IPW) to assign each device a weight, i.e., the reverse of the phone users’ count ratio to the DeSO zone’s actual adult population size (Wp).\n",
    "- we fit the calculated weights to the work activity participation rates by deso zone, to ensure that the work activity participation rate is accurately captured. E.g., 60% of people participate in work activity by the survey, but we detect only 20% work activity participation in the data.  By the statistic, the weight of the devices with work activity is increased and the weight of the devices with no work activity is decreased.\n",
    "- we apply weight trimming technique, where any weight above the cut-point weight (W0) is set to W0."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "gdf_2_home.loc[:, 'wt'] = gdf_2_home.loc[:, 'adult_pop'] / gdf_2_home.loc[:, 'home_count']\n",
    "gdf_2_home.loc[:, 'wt_p'] = gdf_2_home.loc[:, 'adult_pop'] / gdf_2_home.loc[:, 'home_count']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "#w0 = ((np.std(gdf_2_home.loc[:, 'wt_p']) / np.mean(gdf_2_home.loc[:, 'wt_p'])) ** 2 + 1) ** 0.5 * 3.5 * np.median(   gdf_2_home.loc[:, 'wt_p'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population above 17 years old:  8060839.0\n"
     ]
    }
   ],
   "source": [
    "#gdf_2_home.loc[gdf_2_home['wt_p'] > w0, 'wt_p'] = w0\n",
    "\n",
    "print('Population above 17 years old: ',np.sum(gdf_2_home['wt'] * gdf_2_home['home_count']))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "employees = df_act['uid'][df_act.work_potential== 1].unique()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "gdf_act = gdf_act[gdf_act.home_potential == 1]\n",
    "gdf_act['work_potential'][gdf_act.uid.isin(employees)] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "gdf_act = pd.merge(gdf_act, gdf_2_home[['Deso','wt','wt_p']], on='Deso', how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [],
   "source": [
    "df_act = gdf_act[['uid', 'Deso', 'work_potential', 'adult_pop', 'employee_pop', 'work_par_pop','wt' , 'wt_p']].sort_values(by=['Deso'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "def ipf_wtp(data):\n",
    "    current_pop = data['wt'].sum()\n",
    "    #pop_factor = current_pop/data['adult_pop']\n",
    "    for it in range(20):\n",
    "\n",
    "        employees = data['wt'][data['work_potential']==1].sum() #* pop_factor\n",
    "        data['wt'][data['work_potential']==1] = data['wt'][data['work_potential']==1] * (data['employee_pop']/ employees)\n",
    "        population = data['wt'].sum()\n",
    "        data['wt'] = data['wt'] * (current_pop/ population)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5985 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7958cec9738142c7957659db688b04a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tqdm.pandas()\n",
    "df_act = df_act.groupby('Deso').progress_apply(ipf_wtp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of all weights 7722118.9950764775\n"
     ]
    }
   ],
   "source": [
    "w0 = ((np.std(df_act.loc[:, 'wt']) / np.mean(df_act.loc[:, 'wt'])) ** 2 + 1) ** 0.5 * 3.5 * np.median( df_act.loc[:, 'wt'])\n",
    "df_act.loc[df_act['wt'] > w0, 'wt'] = w0\n",
    "print('sum of all weights', df_act['wt'].sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def ipf_wtp(data):\n",
    "    current_pop = data['wt_p'].sum()\n",
    "    #pop_factor = current_pop/data['adult_pop']\n",
    "    for it in range(20):\n",
    "\n",
    "        employees = data['wt_p'][data['work_potential']==1].sum() #* pop_factor\n",
    "        data['wt_p'][data['work_potential']==1] = data['wt_p'][data['work_potential']==1] * (data['work_par_pop']/ employees)\n",
    "        population = data['wt_p'].sum()\n",
    "        data['wt_p'] = data['wt_p'] * (current_pop/ population)\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5985 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be82f103abec4a37b4e8fc875dd1c9d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the weight by work activity participation\n",
    "\n",
    "tqdm.pandas()\n",
    "df_act = df_act.groupby('Deso').progress_apply(ipf_wtp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of all weights 7964673.298823298\n"
     ]
    }
   ],
   "source": [
    "w0 = ((np.std(df_act.loc[:, 'wt_p']) / np.mean(df_act.loc[:, 'wt_p'])) ** 2 + 1) ** 0.5 * 3.5 * np.median( df_act.loc[:, 'wt_p'])\n",
    "df_act.loc[df_act['wt_p'] > w0, 'wt_p'] = w0\n",
    "print('sum of all weights', df_act['wt_p'].sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "# save the table\n",
    "df_act.drop(['adult_pop', 'employee_pop', 'work_par_pop'], axis=1, inplace=True)\n",
    "df_act.to_parquet(f'./dbs/intermediate/indi_weights.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# def ipf_wtp(data):\n",
    "#     current_pop = data['wt_p'].sum()\n",
    "#     #pop_factor = current_pop/data['adult_pop']\n",
    "#     std_eror =10\n",
    "#     while std_eror >  0.0001:\n",
    "#\n",
    "#         employees = data['wt_p'][data['work_potential']==1].sum() #* pop_factor\n",
    "#         data['wt_p'][data['work_potential']==1] = data['wt_p'][data['work_potential']==1] * (data['employee_pop']/ employees)\n",
    "#         population = data['wt_p'].sum()\n",
    "#         wt_p_old = data['wt_p']\n",
    "#\n",
    "#         data['wt_p'] = data['wt_p'] * (current_pop/ population)\n",
    "#         std_eror = np.sqrt(np.sum(np.square((wt_p_old - data['wt_p'])))/len(data))\n",
    "#\n",
    "#\n",
    "#     return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# tqdm.pandas()\n",
    "# df_act1 = df_act.groupby('Deso').progress_apply(ipf_wtp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
