{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "C:\\MAD4AG\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd C:\\MAD4AG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import geopandas\n",
    "from scipy.spatial import distance\n",
    "import pyproj as proj\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## filter ppl by\n",
    "- participating work activity\n",
    "- county\n",
    "- urban/rural\n",
    "- commute distance (is it above or below the median in the survey)\n",
    "- avg trip distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "file_name = f'./dbs/intermediate/stops_1_new.parquet'\n",
    "\n",
    "\n",
    "df_clusters = pd.read_parquet(file_name)\n",
    "df_clusters = df_clusters[df_clusters.holiday_s != 1]\n",
    "df_clusters = df_clusters[df_clusters.weekday_s == 1]\n",
    "df_clusters = df_clusters.drop(['holiday_s', 'weekday_s'], axis=1)\n",
    "\n",
    "df_clusters.drop_duplicates(subset=['uid', 'cluster'], keep='first', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# read home clusters\n",
    "\n",
    "\n",
    "df_h = pd.read_parquet(f'./dbs/intermediate/home_inference.parquet')\n",
    "df_h.drop_duplicates(subset='uid', keep='first', inplace=True)\n",
    "\n",
    "df_h['home_potential'] = 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# read work clusters, keep only ppl having home locations\n",
    "\n",
    "df_w = pd.read_parquet(f'./dbs/intermediate/work_inference.parquet')\n",
    "df_w.drop_duplicates(subset='uid', keep='first', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# keep ppl having home locations\n",
    "\n",
    "df_clusters = df_clusters[['uid', 'cluster', 'cluster_lat', 'cluster_lng']]\n",
    "\n",
    "df_clusters = df_clusters[df_clusters.uid.isin(df_h.uid.unique())]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# add home information to clusters\n",
    "\n",
    "df_clusters = pd.merge(df_clusters, df_h[['uid', 'cluster','home_potential' ]], on=['uid','cluster'], how='left' )\n",
    "\n",
    "df_clusters.rename(columns={'home_potential':'act_type'}, inplace=True)\n",
    "\n",
    "df_clusters['act_type'] = df_clusters.act_type.replace(1, 'home')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# add work information to clusters\n",
    "\n",
    "\n",
    "df_clusters = pd.merge(df_clusters, df_w[['uid', 'cluster','work_potential' ]], on=['uid','cluster'], how='left' )\n",
    "\n",
    "df_clusters['act_type'][df_clusters.work_potential==1.00000]='work'\n",
    "\n",
    "df_clusters.drop(['work_potential'], axis=1, inplace=True)\n",
    "\n",
    "df_clusters['act_type'] = df_clusters['act_type'].fillna('other')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## calculate the average distance between the home and all activity clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# setup your projections\n",
    "crs_wgs = proj.Proj(init='epsg:4326') # assuming you're using WGS84 geographic\n",
    "crs_bng = proj.Proj(init='epsg:3006') # use a locally appropriate projected CRS\n",
    "\n",
    "# then cast your geographic coordinate pair to the projected system\n",
    "df_clusters['X'], df_clusters['Y']  = proj.transform(crs_wgs, crs_bng, df_clusters.cluster_lng.values, df_clusters.cluster_lat.values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "df_clusters.to_parquet(f'./dbs/intermediate/df_selected_clusters.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def avg_dist(data):\n",
    "\n",
    "\n",
    "    avg_dist = distance.cdist(data[['X', 'Y']][data.act_type=='home'], data[['X', 'Y']][data.act_type!='home'], metric='euclidean')\n",
    "\n",
    "    avg_dist = np.median(avg_dist, axis=1)\n",
    "\n",
    "\n",
    "    return pd.Series(dict(avg_dist=float(avg_dist)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/280996 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3727b6b549b4105a8c90f962c7e5206"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_clusters_avg_dist = df_clusters.groupby('uid').progress_apply(avg_dist).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## calculate the commuting distance between the home and all activity clusters."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "def com_dist(data):\n",
    "\n",
    "\n",
    "    dist_data = distance.cdist(data[['X', 'Y']][data.act_type=='home'], data[['X', 'Y']][data.act_type=='work'], metric='euclidean')\n",
    "\n",
    "    dist_data = np.mean(dist_data, axis=1)\n",
    "\n",
    "    return pd.Series(dict(com_dist=float(dist_data)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/280996 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2096494f4ba3465487509a2cb490f3b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df_clusters_com_dist = df_clusters.groupby('uid').progress_apply(com_dist).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "df_act = pd.read_parquet(f'./dbs/intermediate/indi_weights.parquet')\n",
    "\n",
    "df_act['county']= df_act['Deso'].str[:2]\n",
    "\n",
    "df_act['urban_density']= df_act['Deso'].str[4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_act = pd.merge(df_act, df_clusters_avg_dist, on='uid' )\n",
    "df_act = pd.merge(df_act,  df_clusters_com_dist, on='uid')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "df_act.dropna(subset=['avg_dist'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# save the table\n",
    "df_act = df_act[['uid', 'work_potential', 'Deso', 'county', 'urban_density', 'avg_dist',\n",
    "       'com_dist', 'wt', 'wt_p']]\n",
    "\n",
    "df_act.rename(columns={'work_potential':\"commute\"},inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "\n",
    "df_act.to_parquet(f'./dbs/intermediate/indi_weights.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
