{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\MAD4AG\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\MAD4AG\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "file = r'.\\dbs\\twins\\multiple_days_03-21.pkl'\n",
    "\n",
    "combined_df= pd.read_pickle(file)\n",
    "\n",
    "\n",
    "df_clusters=pd.read_parquet(f'./dbs/intermediate/df_selected_clusters.parquet')\n",
    "\n",
    "df_clusters = df_clusters[df_clusters.uid.isin(combined_df.uid)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  6.574893589054653\n",
      "median:  3.0\n",
      "the share of people more than 10 other clusters:  0.18115956036139128\n"
     ]
    },
    {
     "data": {
      "text/plain": "1.0      57089\n2.0      43543\n3.0      28524\n4.0      20042\n5.0      15291\n         ...  \n149.0        1\n331.0        1\n137.0        1\n139.0        1\n146.0        1\nName: number_of_other_cluster, Length: 161, dtype: int64"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean and median of the number_of_other_cluster in MAD data\n",
    "\n",
    "\n",
    "df_clusters_statistic= df_clusters[df_clusters.act_type=='other'].groupby(['uid']).size().reset_index(name='number_of_other_cluster')\n",
    "\n",
    "df_clusters_statistic = pd.merge(combined_df[['uid']], df_clusters_statistic, on='uid', how='left')\n",
    "df_clusters_statistic.fillna(0, inplace=True)\n",
    "\n",
    "print('mean: ', df_clusters_statistic.number_of_other_cluster.mean())\n",
    "print('median: ', df_clusters_statistic.number_of_other_cluster.median())\n",
    "print('the share of people more than 10 other clusters: ',len(df_clusters_statistic[df_clusters_statistic.number_of_other_cluster>10])/len(df_clusters_statistic))\n",
    "df_clusters_statistic.number_of_other_cluster.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "file_name = f'./dbs/intermediate/stops_1_new.parquet'\n",
    "\n",
    "#Read each batchs file\n",
    "df = pd.read_parquet(file_name)\n",
    "df = df[df.holiday_s != 1]\n",
    "df = df[df.weekday_s == 1]\n",
    "df = df.drop(['holiday_s', 'weekday_s'], axis=1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "df_clusters_freq = df.groupby(['uid','cluster']).size().reset_index(name='clusters_freq')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "df_clusters = pd.merge(df_clusters, df_clusters_freq, on=['uid','cluster'], how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/258667 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f75fbdab128e4fa7a998753cb004914c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def other_dist(data):\n",
    "    avg_dist = distance.cdist(data[['X', 'Y']][data.act_type == 'home'], data[['X', 'Y']],  metric='euclidean')\n",
    "    data['distance']= avg_dist[0]\n",
    "\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "df_clusters = df_clusters.groupby('uid').progress_apply(other_dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "df_clusters_other = df_clusters[df_clusters.act_type=='other']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# apply inverse logarithmic function shifted 1 unit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "\n",
    "df_clusters_other['distance'][df_clusters_other['distance']==0.00000]=100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "df_clusters_other['scaled_distances'] = df_clusters_other['distance'].apply(lambda x: 1/np.log(x+1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "df_clusters_other['clusters_freq']= df_clusters_other['clusters_freq']*df_clusters_other['scaled_distances']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "df_clusters_other['freq_sum'] = df_clusters_other.groupby(['uid'])['clusters_freq'].transform(\"sum\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df_clusters_other['other_prob'] = df_clusters_other['clusters_freq']/df_clusters_other['freq_sum']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "df_clusters_list= df_clusters_other.groupby(['uid'])['cluster'].apply(list).reset_index(name='clusters')\n",
    "\n",
    "df_other_prob_list = df_clusters_other.groupby(['uid'])['other_prob'].apply(list).reset_index(name='other_prob')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "df_other = pd.merge(combined_df[['uid', 'other_count_0', 'other_count_1', 'other_count_2', 'other_count_3', 'other_count_4']],  df_clusters_list, on='uid', how='left')\n",
    "df_other = pd.merge(df_other, df_other_prob_list, on='uid', how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "df_other = df_other.dropna(subset=['clusters'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sample other activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# def other_finder(data , i):\n",
    "#     other_clusters_place = np.argmax(np.random.multinomial(1, data['other_prob'], data['other_count_'+ str(i)]), axis=1).tolist()\n",
    "#     clusters_list = data['clusters']\n",
    "#     other_clusters = [clusters_list[place] for place in other_clusters_place]\n",
    "#     return other_clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def other_finder(data , i):\n",
    "    clusters_list = data['clusters']\n",
    "    sample_size = data['other_count_'+ str(i)]\n",
    "    if len(clusters_list)>= sample_size:\n",
    "        other_clusters = np.random.choice(clusters_list, sample_size, p=data['other_prob'], replace=False).tolist()\n",
    "    else:\n",
    "        other_clusters = np.random.choice(clusters_list, len(clusters_list), p=data['other_prob'], replace=False).tolist()\n",
    "        other_clusters += np.random.choice(clusters_list, sample_size-len(clusters_list), p=data['other_prob'], replace=True).tolist()\n",
    "    random.shuffle(other_clusters)\n",
    "\n",
    "    return other_clusters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    column_name= 'other_clusters_'+str(i)\n",
    "    df_other[column_name] = df_other.apply(lambda row: other_finder(row, i), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## show the selected other activities in the activity clusters dataframe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "df_clusters_other_select=pd.merge(df_clusters_other[['uid','cluster']], df_other[['uid','other_clusters_0','other_clusters_1','other_clusters_2','other_clusters_3','other_clusters_4']], on='uid', how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#df_clusters5.dropna(subset=['other_clusters_0'],inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def other_selection(data, i):\n",
    "    if data['cluster'] in data['other_clusters_' + str(i)]:\n",
    "        selection='1'\n",
    "    else:\n",
    "        selection='0'\n",
    "    return selection\n",
    "\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    column_name = 'selection_' + str(i)\n",
    "    df_clusters_other_select[column_name] = df_clusters_other_select.apply(lambda row: other_selection(row, i), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# df_clusters = pd.merge(df_clusters, df_clusters_other_select[['uid','cluster','selection_0','selection_1','selection_2','selection_3','selection_4']], on= ['uid','cluster'], how='left' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "df_clusters = pd.merge(df_clusters, df_clusters_other_select, on= ['uid','cluster'], how='left' )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "df_clusters['selection_0'][df_clusters.act_type=='home']='Home'\n",
    "df_clusters['selection_1'][df_clusters.act_type=='home']='Home'\n",
    "df_clusters['selection_2'][df_clusters.act_type=='home']='Home'\n",
    "df_clusters['selection_3'][df_clusters.act_type=='home']='Home'\n",
    "df_clusters['selection_4'][df_clusters.act_type=='home']='Home'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "df_clusters['selection_0'][df_clusters.act_type=='work']='Work'\n",
    "df_clusters['selection_1'][df_clusters.act_type=='work']='Work'\n",
    "df_clusters['selection_2'][df_clusters.act_type=='work']='Work'\n",
    "df_clusters['selection_3'][df_clusters.act_type=='work']='Work'\n",
    "df_clusters['selection_4'][df_clusters.act_type=='work']='Work'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# df_clusters['selection_0'][df_clusters.act_type=='school']='School'\n",
    "# df_clusters['selection_1'][df_clusters.act_type=='school']='School'\n",
    "# df_clusters['selection_2'][df_clusters.act_type=='school']='School'\n",
    "# df_clusters['selection_3'][df_clusters.act_type=='school']='School'\n",
    "# df_clusters['selection_4'][df_clusters.act_type=='school']='School'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## calculate the distances from work location"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/258667 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ef72981dc8d74dbe946cee5ad26bfada"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def other_dist(data):\n",
    "    if len(data[data['act_type'] == 'work'])>0:\n",
    "        avg_dist = distance.cdist(data[['X', 'Y']][data.act_type == 'work'], data[['X', 'Y']],  metric='euclidean')\n",
    "        data['work_dist']= avg_dist[0]\n",
    "    else:\n",
    "        data['work_dist']= 0\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "df_clusters = df_clusters.groupby('uid').progress_apply(other_dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mark the unselected activities as non"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "df_clusters.loc[:, ['selection_0','selection_1','selection_2','selection_3','selection_4']] = df_clusters.loc[:, ['selection_0','selection_1','selection_2','selection_3','selection_4']].replace({'1': 'Other','0': 'non'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "filename = r'.\\dbs\\intermediate\\df_selected_clusters_activities%s.parquet'%file[25:31]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "\n",
    "df_clusters.to_parquet(filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
