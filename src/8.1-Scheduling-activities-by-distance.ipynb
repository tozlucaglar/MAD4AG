{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\MAD4AG\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%cd C:\\MAD4AG\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "filename = r'.\\dbs\\twins\\multiple_days_03-21.pkl'\n",
    "\n",
    "combined_df= pd.read_pickle(filename)\n",
    "#combined_df.columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_clusters=pd.read_parquet(f'./dbs/intermediate/df_selected_clusters_activities_03-21.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_survey_act = pd.read_pickle(f'./dbs/intermediate/survey_act_weekday_modified.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generate activity schedule for simulation #1\n",
    "- by merging survey activity sequence table\n",
    "- the survey activity sequence table brings activity sequences and activity start end times"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias day\n"
     ]
    }
   ],
   "source": [
    "day = '3'\n",
    "%store -r day\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_act_schedule_0 = pd.merge(combined_df[['uid', 'employee', 'Deso', 'wt', 'wt_p', 'sub_id_'+day,'act_seq_simp_'+day]], df_survey_act[['sub_id', 'purpose','h_s','h_e']], left_on='sub_id_'+day,right_on='sub_id')\n",
    "\n",
    "df_act_schedule_0['act_seq'] = df_act_schedule_0.groupby('uid').cumcount()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### add sequence information of other activities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df_act_schedule_0['other_order']= 0\n",
    "\n",
    "df_act_schedule_0['other_order'][df_act_schedule_0.purpose=='Other'] = df_act_schedule_0[df_act_schedule_0.purpose=='Other'].groupby('uid').cumcount()\n",
    "\n",
    "df_act_schedule_0['other_order']=df_act_schedule_0['other_order'].astype(str)\n",
    "\n",
    "df_act_schedule_0['purpose'][df_act_schedule_0.purpose=='Other']= df_act_schedule_0['purpose'][df_act_schedule_0.purpose=='Other'] + df_act_schedule_0['other_order'][df_act_schedule_0.purpose=='Other']\n",
    "\n",
    "df_act_schedule_0.drop(columns=['other_order'] ,inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## re-organise df_cluster table by the other activities order and repetition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "df_clusters_0 = df_clusters[['uid','cluster','other_clusters_'+day,'selection_'+day, 'X','Y','cluster_lat','cluster_lng']][df_clusters['selection_'+day] != 'non']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_clusters_0_other = df_clusters_0[df_clusters_0['selection_'+day] =='Other']\n",
    "\n",
    "\n",
    "df_other_org = df_clusters_0_other[['uid', 'other_clusters_'+day]]\n",
    "df_other_org= df_other_org.drop_duplicates(subset='uid')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# it will transform each element of the list in the cloumn 'other_cluster_O' to a row.\n",
    "\n",
    "df_other_org = df_other_org.explode('other_clusters_'+day)\n",
    "\n",
    "df_other_org.rename(columns={'other_clusters_'+day:'cluster'}, inplace=True)\n",
    "\n",
    "df_other_org['other_order'] = df_other_org.groupby('uid').cumcount()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_other_org = pd.merge(df_other_org, df_clusters_0_other, on=['uid', 'cluster'],how='left')\n",
    "\n",
    "# add sequence information of other activities\n",
    "\n",
    "df_other_org['other_order'] = df_other_org['other_order'].astype(str)\n",
    "\n",
    "df_other_org['selection_'+day]= df_other_org['selection_'+day]+ df_other_org['other_order']\n",
    "\n",
    "df_other_org.drop(columns=['other_order'] ,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df_clusters_0 = df_clusters_0[df_clusters_0['selection_'+day] !='Other']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "df_clusters_0 = pd.concat([df_clusters_0, df_other_org], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "df_clusters_0.drop(columns=['other_clusters_'+day] ,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "df_act_schedule_0 = pd.merge(df_act_schedule_0, df_clusters_0, left_on=['uid','purpose'],right_on=['uid','selection_'+day], how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "df_act_schedule_0.drop(columns=['selection_'+day] ,inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_act_schedule_0.rename(columns={'cluster_lat':'lat','cluster_lng':'lng'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_act_schedule_0['purpose'][ ~df_act_schedule_0['purpose'].isin(['Home', 'Work'])] = df_act_schedule_0['purpose'][ ~df_act_schedule_0['purpose'].isin(['Home', 'Work'])].str[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# file = r'.\\dbs\\twins\\%s-schedule-%s.pkl'%(filename[26:31],day)\n",
    "#\n",
    "# df_act_schedule_0.to_pickle(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### activity schedules are ready here. But other activities are not ordered by distances"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "df_clusters_distances = df_clusters[['uid','cluster','other_clusters_'+day,'selection_'+day, 'X','Y','cluster_lat','cluster_lng','distance', 'work_dist']][df_clusters['selection_'+day] != 'non']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# from scipy.spatial import distance\n",
    "# from tqdm.auto import tqdm\n",
    "#\n",
    "#\n",
    "#\n",
    "# def other_dist(data):\n",
    "#\n",
    "#     if len(data[data['selection_'+day] == 'Work'])>0:\n",
    "#         work_dist = distance.cdist(data[['X', 'Y']][data['selection_'+day] == 'Work'].head(1), data[['X', 'Y']],  metric='euclidean')\n",
    "#         data['work_dist']= work_dist[0]\n",
    "#\n",
    "#     return data\n",
    "#\n",
    "#\n",
    "# tqdm.pandas()\n",
    "# df_clusters_distances = df_clusters_distances.groupby('uid').progress_apply(other_dist)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# df_clusters_distances['work_dist']= df_clusters_distances['work_dist'].fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "df_clusters_distances_other = df_clusters_distances[df_clusters_distances['selection_'+day]=='Other']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "outputs": [],
   "source": [
    "df_clusters_distances_other = df_clusters_distances_other[['uid','other_clusters_'+day]].drop_duplicates(subset=['uid'])\n",
    "df_clusters_distances_other = df_clusters_distances_other.explode('other_clusters_'+day)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [],
   "source": [
    "df_clusters_distances_other = pd.merge(df_clusters_distances_other , df_clusters_distances[['uid','cluster', 'distance', 'work_dist']], left_on=['uid','other_clusters_'+day ],right_on=['uid','cluster'], how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "outputs": [],
   "source": [
    "df_clusters_distances_other_home= df_clusters_distances_other.sort_values(by=['uid','distance'])\n",
    "df_clusters_distances_other_home= df_clusters_distances_other_home.groupby('uid')['cluster'].apply(list).reset_index(name='other_cluster_dist')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "outputs": [],
   "source": [
    "df_clusters_distances_other_work= df_clusters_distances_other.sort_values(by=['uid','work_dist'])\n",
    "df_clusters_distances_other_work= df_clusters_distances_other_work.groupby('uid')['cluster'].apply(list).reset_index(name='other_cluster_work_dist')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## select ppl having more than one other in their schedule"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "outputs": [],
   "source": [
    "modified_ppl = df_act_schedule_0[df_act_schedule_0.purpose=='Other'].groupby(['uid']).size().reset_index(name='count')\n",
    "modified_ppl = modified_ppl['uid'][modified_ppl['count']>1].unique()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "\n",
    "ppl_other =df_act_schedule_0[df_act_schedule_0.uid.isin(modified_ppl)]\n",
    "\n",
    "ppl_other= ppl_other.sort_values(by=['uid','act_seq'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "# ppl_other = pd.merge(ppl_other, df_clusters_distances[['uid','cluster','distance','work_dist']], on= ['uid','cluster'], how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "outputs": [],
   "source": [
    "ppl_other = ppl_other[['uid', 'act_seq_simp_'+day, 'cluster']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [],
   "source": [
    "ppl_other_cluster= ppl_other.groupby('uid')['cluster'].apply(list).reset_index(name='cluster_list')\n",
    "\n",
    "ppl_other = ppl_other.drop_duplicates(subset=['uid'])\n",
    "\n",
    "\n",
    "ppl_other = pd.merge(ppl_other[['uid', 'act_seq_simp_'+day]],ppl_other_cluster, on='uid' )\n",
    "ppl_other = pd.merge(ppl_other,df_clusters_distances_other_home, on='uid' ,how='left')\n",
    "ppl_other = pd.merge(ppl_other,df_clusters_distances_other_work, on='uid' ,how='left')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [],
   "source": [
    "def seq_modifier(data):\n",
    "    alist = list(data['act_seq_simp_'+day])\n",
    "    cluster_list_new = data['cluster_list'].copy()\n",
    "    home_other = data['other_cluster_dist'].copy()\n",
    "    work_other = data['other_cluster_work_dist'].copy()\n",
    "    anc_type = None  # Initialize anc_type before the loop\n",
    "    for i in range(0, len(alist) - 1, 1):\n",
    "        if alist[i] in ['Home','Work']:\n",
    "            # anc_type='Home'\n",
    "            anc_type=alist[i]\n",
    "        # elif alist[i] in ['Work']:\n",
    "        #     anc_type='Work'\n",
    "        elif alist[i] in ['Other']:\n",
    "            if anc_type=='Home':\n",
    "                cluster_list_new.insert(i, home_other[0])\n",
    "                del cluster_list_new[i+1]\n",
    "                del home_other[0]\n",
    "                del work_other[0]\n",
    "            elif anc_type=='Work':\n",
    "                cluster_list_new.insert(i, work_other[0])\n",
    "                del cluster_list_new[i+1]\n",
    "                del home_other[0]\n",
    "                del work_other[0]\n",
    "\n",
    "\n",
    "    data['cluster_list_new'] = cluster_list_new\n",
    "    return data\n",
    "\n",
    "tqdm.pandas()\n",
    "ppl_other = ppl_other.apply(lambda row: seq_modifier(row), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "ppl_other = ppl_other[['uid','cluster_list_new']]\n",
    "\n",
    "ppl_other.sort_values(by=['uid'], inplace=True)\n",
    "\n",
    "ppl_other = ppl_other.explode('cluster_list_new')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "df_act_schedule_0_modified =df_act_schedule_0[df_act_schedule_0.uid.isin(modified_ppl)]\n",
    "\n",
    "df_act_schedule_0_modified = df_act_schedule_0_modified.sort_values(by=['uid','act_seq'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [],
   "source": [
    "#df_act_schedule_0_modified[df_act_schedule_0_modified.uid=='fffd8cc1-2544-4393-9011-edd0a1f75e70-1']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "df_act_schedule_0_modified['cluster']= ppl_other['cluster_list_new'].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [],
   "source": [
    "#df_act_schedule_0_modified[df_act_schedule_0_modified.uid=='fffd8cc1-2544-4393-9011-edd0a1f75e70-1']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "df_act_schedule_0_modified.drop(columns=['X', 'Y','lat', 'lng'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [],
   "source": [
    "df_act_schedule_0_modified = pd.merge(df_act_schedule_0_modified, df_clusters[['uid','cluster','X', 'Y','cluster_lat', 'cluster_lng']], on=['uid','cluster'], how='left')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [],
   "source": [
    "df_act_schedule_0_modified.rename(columns={'cluster_lat':'lat', 'cluster_lng':'lng'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "df_act_schedule_0_not_modified =df_act_schedule_0[~df_act_schedule_0.uid.isin(modified_ppl)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [
    "df_act_schedule = pd.concat([df_act_schedule_0_not_modified, df_act_schedule_0_modified], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "file = r'.\\dbs\\twins\\%s-schedule-%s.pkl'%(filename[26:31],day)\n",
    "\n",
    "df_act_schedule.to_pickle(file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
