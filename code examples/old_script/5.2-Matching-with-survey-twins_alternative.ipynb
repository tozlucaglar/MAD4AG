{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "C:\\MAD4AG\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd C:\\MAD4AG\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "df_MAD = pd.read_parquet(f'./dbs/intermediate/indi_weights.parquet')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "df_survey_twins = pd.read_pickle(f'./dbs/intermediate/df_survey_twins.pkl')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# add region information"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "lan= pd.read_csv(f'./dbs/lan.csv', delimiter=';', dtype={'code':'string'})\n",
    "lan.rename(columns={'code':'county', 'landsdelar':'region'},inplace=True)\n",
    "\n",
    "df_MAD = pd.merge(df_MAD, lan[['county','region']], on='county')\n",
    "df_survey_twins = pd.merge(df_survey_twins, lan[['county','region']], on='county')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# calculate median distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "avg_dist_threshold = df_survey_twins.avg_dist.median()\n",
    "com_dist_threshold = df_survey_twins.com_distance.median()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# create stratum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "df_MAD['region'] = df_MAD['region'].replace({'Svealand':'0','Göteland':'1', 'Norrland':'2'})\n",
    "\n",
    "df_MAD['urban_density'] = df_MAD['urban_density'].replace({'A': '0', 'B': '1', 'C': '1'})\n",
    "\n",
    "df_MAD['avg_dist_cat'] = '0'\n",
    "df_MAD['avg_dist_cat'][df_MAD.avg_dist > avg_dist_threshold] = '1'\n",
    "\n",
    "# df_MAD['com_dist_cat'] = '0'\n",
    "# df_MAD['com_dist_cat'][df_MAD.com_dist > com_dist_threshold] = '1'\n",
    "\n",
    "df_MAD.rename(columns={'commute':'employee'}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "0101    48915\n0100    37723\n1101    34118\n1100    33219\n0111    13312\n1110    13226\n1111    12411\n2100    11705\n0110    11580\n2101     7158\n1001     6322\n0001     4944\n2110     4158\n1011     3365\n1000     3215\n2111     2502\n2001     2399\n0011     2054\n0000     1899\n2000     1344\n2011     1136\n1010     1055\n0010      561\n2010      346\nName: stratum, dtype: int64"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_MAD['stratum'] = df_MAD['region'].astype(str) + df_MAD['urban_density'].astype(str) +  df_MAD['employee'].astype(str)+  df_MAD['avg_dist_cat'].astype(str)\n",
    "\n",
    "# df_MAD['stratum'][(df_MAD.commute == 1)] = df_MAD['stratum'][(df_MAD.commute == 1)] + df_MAD['com_dist_cat'][(df_MAD.commute == 1)].astype(str)\n",
    "\n",
    "df_MAD['stratum'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [],
   "source": [
    "df_survey_twins['region'] = df_survey_twins['region'].replace({'Svealand':'0','Göteland':'1', 'Norrland':'2'})\n",
    "\n",
    "df_survey_twins['urban_density'] = df_survey_twins['urban_density'].replace({'A': '0', 'B': '1', 'C': '1'})\n",
    "\n",
    "df_survey_twins['avg_dist_cat'] = '0'\n",
    "df_survey_twins['avg_dist_cat'][df_survey_twins.avg_dist > avg_dist_threshold] = '1'\n",
    "\n",
    "# df_survey_twins['com_dist_cat'] = '0'\n",
    "# df_survey_twins['com_dist_cat'][df_survey_twins.com_distance > com_dist_threshold] = '1'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "1111    3006\n1110    2953\n1100    1719\n0110    1309\n0111    1256\n1101     869\n1011     868\n0100     724\n1001     339\n0101     330\n2110     316\n0011     243\n2100     168\n2111     153\n1010     145\n2011     132\n0001     103\n1000      78\n2001      78\n2101      61\n0010      16\n0000       8\n2010       3\nName: stratum, dtype: int64"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_survey_twins['stratum'] = df_survey_twins['region'].astype(str) + df_survey_twins['urban_density'].astype(str) +  df_survey_twins['employee'].astype(str)+  df_survey_twins['avg_dist_cat'].astype(str)\n",
    "\n",
    "# df_survey_twins['stratum'][(df_survey_twins.commute == 1)] = df_survey_twins['stratum'][(df_survey_twins.commute == 1)] + df_survey_twins['com_dist_cat'][(df_survey_twins.commute == 1)].astype(str)\n",
    "\n",
    "df_survey_twins['stratum'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "list_survey_type = list(df_survey_twins['stratum'].unique())\n",
    "list_MAD_type = list(df_MAD['stratum'].unique())\n",
    "\n",
    "\n",
    "#set(list_MAD_type).difference(set(list_survey_type))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "threshold_count = 50\n",
    "\n",
    "df_stratum = pd.DataFrame(columns=['stratum','level','mad_size','sample_size' , 'sur_size','survey_ppl'])\n",
    "\n",
    "\n",
    "for i in list_MAD_type:\n",
    "    df_MAD_p_type = df_MAD[df_MAD['stratum']==i]\n",
    "    #print('mad len: ', len(df_MAD_p_type))\n",
    "\n",
    "    df_sur_p_type = df_survey_twins[df_survey_twins['region']==i[0]]\n",
    "\n",
    "    df_sur_temp = df_sur_p_type\n",
    "    level = 0\n",
    "    if len(df_sur_p_type) > threshold_count:\n",
    "        df_sur_temp = df_sur_p_type[df_sur_p_type['urban_density']==i[1]]\n",
    "        level = 1\n",
    "        if len(df_sur_temp) > threshold_count:\n",
    "            df_sur_p_type = df_sur_temp\n",
    "            df_sur_temp = df_sur_p_type[df_sur_p_type['employee']==int(i[2])]\n",
    "            level = 2\n",
    "            #print(level)\n",
    "            if len(df_sur_temp) > threshold_count:\n",
    "                df_sur_p_type = df_sur_temp\n",
    "                df_sur_temp = df_sur_p_type[df_sur_p_type['avg_dist_cat']==i[3]]\n",
    "                level = 3\n",
    "                #print(int(i[2]))\n",
    "                if len(df_sur_temp) > threshold_count:\n",
    "                   df_sur_p_type = df_sur_temp\n",
    "                   level = 4\n",
    "\n",
    "                # elif (len(df_sur_temp) > threshold_count)&(int(i[2])==1):\n",
    "                #     df_sur_p_type = df_sur_temp\n",
    "                #     df_sur_temp = df_sur_p_type[df_sur_p_type['com_dist_cat']==i[4]]\n",
    "                #     level = 4\n",
    "                #     #print(level)\n",
    "                #\n",
    "                #     if len(df_sur_temp) > threshold_count:\n",
    "                #         df_sur_p_type = df_sur_temp\n",
    "                #         level = 5\n",
    "\n",
    "    df_stratum = df_stratum.append(dict(stratum=i, level=level, mad_size=df_MAD_p_type.wt.sum(), sample_size=len(df_MAD_p_type), sur_size=len(df_sur_p_type), survey_ppl=df_sur_p_type['sub_id'].tolist()), ignore_index=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## simplify activity sequences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "\n",
    "# def act_seq_simplifier(data):\n",
    "#     alist = list(data['act_seq'])\n",
    "#     counter = 0\n",
    "#     for i in range(len(alist) - 1, 0, -1):\n",
    "#         if alist[i] in ['Home', 'Work', 'School']:\n",
    "#             counter = 0\n",
    "#             if alist[i] == alist[i-1]:\n",
    "#                 del alist[i]\n",
    "#         elif alist[i] == 'Other':\n",
    "#             counter += 1\n",
    "#             if counter > 3:\n",
    "#                 del alist[i]\n",
    "#     data['act_uniq'] = tuple(alist)\n",
    "#     return data\n",
    "\n",
    "# tqdm.pandas()\n",
    "# df_survey_twins = df_survey_twins.apply(lambda row: act_seq_simplifier(row), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "seq_dist = df_survey_twins.act_seq_simp.value_counts(normalize=True).reset_index(name='count_desired')\n",
    "seq_dist['count_desired']=seq_dist['count_desired']*df_stratum.mad_size.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## generate candidates df by stratums"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "df_candidates = pd.DataFrame(columns=['sub_id', 'act_seq', 'act_seq_simp','stratum','mad_size' ,'ratio'])\n",
    "\n",
    "\n",
    "for index, row in df_stratum.iterrows():\n",
    "\n",
    "    df_temp= df_survey_twins[['sub_id', 'act_seq', 'act_seq_simp']][df_survey_twins.sub_id.isin(row['survey_ppl'])]\n",
    "    df_temp['stratum']= row['stratum']\n",
    "    df_temp['mad_size']=row['mad_size']\n",
    "    df_temp['ratio']=row['mad_size']/row['sur_size']\n",
    "    df_candidates = df_candidates.append(df_temp)\n",
    "    #print(row['survey_ppl'])\n",
    "    #len(df_survey_twins[df_survey_twins.sub_id.isin(row['survey_ppl'])])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "7438637.716134105"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_candidates.ratio.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "#df_candidates.groupby('act_uniq')['ratio'].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## fitting probabilities to the simplified activity seq distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "\n",
    "    #fit to candidates ratios to the act seq distribution\n",
    "    bbb = df_candidates.groupby('act_seq_simp')['ratio'].sum().reset_index(name='count')\n",
    "    merged_df = pd.merge(seq_dist, bbb, left_on='index', right_on='act_seq_simp', how='inner')\n",
    "    merged_df['result_column'] = merged_df['count_desired'] / merged_df['count']\n",
    "    df_candidates = pd.merge(df_candidates, merged_df[['act_seq_simp', 'result_column']], on='act_seq_simp')\n",
    "\n",
    "    df_candidates['ratio']= df_candidates['ratio']*df_candidates['result_column']\n",
    "    df_candidates.drop(columns='result_column', inplace=True)\n",
    "\n",
    "    #here tone down very high probabilities\n",
    "    # w0 = ((np.std(df_candidates.loc[:, 'ratio']) / np.mean(df_candidates.loc[:, 'ratio'])) ** 2 + 1) ** 0.5 * 3.5 * np.median( df_candidates.loc[:, 'ratio'])\n",
    "    # df_candidates.loc[df_candidates['ratio'] > w0, 'ratio'] = w0\n",
    "\n",
    "    #fit to candidates ratios to the mad size by stratum\n",
    "    bbb = df_candidates.groupby('stratum')['ratio'].sum().reset_index(name='count')\n",
    "    df_candidates = pd.merge(df_candidates, bbb, on='stratum')\n",
    "\n",
    "    df_candidates['ratio'] = df_candidates['ratio'] * (df_candidates['mad_size'] / df_candidates['count'])\n",
    "    df_candidates.drop(columns='count', inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sampling survey ppl by the calculated probabilities for each stratum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "df_candidates['probability'] = df_candidates['ratio']/df_candidates['mad_size']\n",
    "\n",
    "#df_MAD['twin_ppl'] =0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "df_candidates_prob= df_candidates.groupby('stratum')['probability'].apply(list).reset_index(name='probability_list')\n",
    "\n",
    "\n",
    "df_candidates_ppl= df_candidates.groupby('stratum')['sub_id'].apply(list).reset_index(name='ppl_list')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "df_stratum = pd.merge(df_stratum, df_candidates_prob)\n",
    "\n",
    "df_stratum = pd.merge(df_stratum, df_candidates_ppl)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "df_stratum['twin_ppl'] = df_stratum.apply( lambda row: np.argmax(np.random.multinomial(1, row['probability_list'], row['sample_size']), axis=1).tolist()  , axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## matching sampled survey ppl with MAD ppl"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "df_survey_twins_new = df_survey_twins.set_index('sub_id')\n",
    "df_survey_twins_new = df_survey_twins_new[['act_seq', 'act_seq_simp', 'avg_dist','commute']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def other_count(data):\n",
    "    act_tuple = data['act_seq_simp']\n",
    "    other_count_seq = Counter(act_tuple).get('Other')\n",
    "    if other_count_seq is not None:\n",
    "        data['other_count_seq'] = other_count_seq\n",
    "    else:\n",
    "        data['other_count_seq'] = 0\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [],
   "source": [
    "\n",
    "tqdm.pandas()\n",
    "df_survey_twins_new = df_survey_twins_new.apply(lambda row: other_count(row), axis=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "# df_twins = pd.DataFrame()\n",
    "#\n",
    "# for index, row in df_stratum.iterrows():\n",
    "#     twin_ppl_list = df_stratum.loc[index,'ppl_list']\n",
    "#     twin_ppl_place = df_stratum.loc[index,'twin_ppl']\n",
    "#     twin_ppl_list = [twin_ppl_list[place] for place in twin_ppl_place]\n",
    "#\n",
    "#     df_survey_candidates= df_survey_twins_new.loc[twin_ppl_list].reset_index()\n",
    "#\n",
    "#     df_survey_candidates.sort_values(by=['other_count_seq','avg_dist'], inplace=True)\n",
    "#     df_survey_candidates.reset_index(inplace=True)\n",
    "#     df_survey_candidates.drop(columns='index', inplace=True)\n",
    "#\n",
    "#     df_MAD_new = df_MAD[df_MAD.stratum==row['stratum']]\n",
    "#     df_MAD_new.sort_values(by=['other_count','avg_dist'], inplace=True)\n",
    "#     df_MAD_new.reset_index(inplace=True)\n",
    "#     df_MAD_new.drop(columns='index', inplace=True)\n",
    "# #\n",
    "#     df_MAD_new = pd.concat([df_MAD_new, df_survey_candidates], axis=1, ignore_index=False)\n",
    "#     df_twins = df_twins.append(df_MAD_new)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "df_twins = pd.DataFrame()\n",
    "\n",
    "for index, row in df_stratum.iterrows():\n",
    "    twin_ppl_list = df_stratum.loc[index,'ppl_list']\n",
    "    twin_ppl_place = df_stratum.loc[index,'twin_ppl']\n",
    "    twin_ppl_list = [twin_ppl_list[place] for place in twin_ppl_place]\n",
    "\n",
    "    df_survey_candidates= df_survey_twins_new.loc[twin_ppl_list].reset_index()\n",
    "\n",
    "    df_MAD_new = df_MAD[df_MAD.stratum==row['stratum']]\n",
    "\n",
    "    zero_MAD = df_MAD_new[df_MAD_new.other_count == 0]\n",
    "    zero_survey = df_survey_candidates[df_survey_candidates.other_count_seq == 0]\n",
    "\n",
    "    #for i in range(len(df_MAD_new.other_count_seq.max())):\n",
    "    if len(zero_MAD) <= len(zero_survey):\n",
    "\n",
    "        zero_survey.sort_values(by=['avg_dist'], inplace=True)\n",
    "        zero_survey.reset_index(inplace=True)\n",
    "        zero_survey = zero_survey.iloc[:len(zero_MAD)]\n",
    "        remain_survey = df_survey_candidates.drop(index=zero_survey.index.to_list())\n",
    "        zero_survey.drop(columns='index', inplace=True)\n",
    "\n",
    "        zero_MAD.sort_values(by=['avg_dist'], inplace=True)\n",
    "        zero_MAD.reset_index(inplace=True)\n",
    "        zero_MAD.drop(columns='index', inplace=True)\n",
    "\n",
    "        zero_MAD = pd.concat([zero_MAD, zero_survey.iloc[:len(zero_MAD)]], axis=1, ignore_index=False)\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(row['stratum'])\n",
    "\n",
    "    df_twins = df_twins.append(zero_MAD)\n",
    "\n",
    "    remain_MAD = df_MAD_new[df_MAD_new.other_count > 0]\n",
    "\n",
    "\n",
    "    remain_survey.sort_values(by=['avg_dist'], inplace=True)\n",
    "    remain_survey.reset_index(inplace=True)\n",
    "    remain_survey.drop(columns='index', inplace=True)\n",
    "\n",
    "    remain_MAD.sort_values(by=['avg_dist'], inplace=True)\n",
    "    remain_MAD.reset_index(inplace=True)\n",
    "    remain_MAD.drop(columns='index', inplace=True)\n",
    "\n",
    "    remain_MAD = pd.concat([remain_MAD, remain_survey], axis=1, ignore_index=False)\n",
    "    df_twins = df_twins.append(remain_MAD)\n",
    "\n",
    "    #print(index)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [],
   "source": [
    "filename = r'.\\dbs\\twins\\run-evaluate_1.pkl'\n",
    "# %store -r filename\n",
    "\n",
    "\n",
    "df_twins.to_pickle(filename)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The share of the matched survey ppl:  0.95\n"
     ]
    }
   ],
   "source": [
    "print('The share of the matched survey ppl: ', np.round(len(df_twins.sub_id.unique())/len(df_survey_twins.sub_id.unique()),2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition number of 10 most matched people \n",
      " 20110931074    196\n",
      "20142021076    195\n",
      "20135211019    195\n",
      "20111611003    194\n",
      "20124851036    194\n",
      "20111541082    190\n",
      "20112511002    189\n",
      "20142641064    189\n",
      "20112221001    185\n",
      "20112621014    184\n",
      "Name: sub_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print('Repetition number of 10 most matched people \\n', df_twins.sub_id.value_counts().head(10))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# code ends here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "data": {
      "text/plain": "65706"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df_twins[(df_twins.employee== 1) ])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "4593"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(df_twins[(df_twins.employee== 1)& (df_twins.commute== 0)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5569376905013758"
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_twins['wt'][(df_twins.employee== 1) ].sum()/df_twins['wt'].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9281932113744805"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_twins['wt'][(df_twins.employee== 1)& (df_twins.commute== 1) ].sum()/df_twins['wt'][(df_twins.employee== 1) ].sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
